{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9606f69",
   "metadata": {},
   "source": [
    "# üìä Ethereum Fraud Detection - Complete Data Analysis & Visualization\n",
    "\n",
    "**Author:** Nopal  \n",
    "**Date:** November 5, 2025  \n",
    "**Thesis:** Ethereum Fraud Detection using XGBoost + SHAP + Network Graph Analysis\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Notebook Overview\n",
    "\n",
    "This notebook provides comprehensive visualization of the entire ML pipeline:\n",
    "\n",
    "1. **Raw Data Exploration** - Transaction data from Ethereum Mainnet\n",
    "2. **Feature Engineering Analysis** - Temporal, Value, Gas, Account Behavior\n",
    "3. **Network Graph Visualization** - Centrality, Community Detection, Risk Propagation\n",
    "4. **Model Training Analysis** - XGBoost hyperparameters, training process\n",
    "5. **SHAP Explainability** - Global & local feature importance\n",
    "6. **Evaluation Metrics** - Confusion Matrix, PR-AUC, ROC curves\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f31c1c",
   "metadata": {},
   "source": [
    "## üîß Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b75a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Network analysis\n",
    "import networkx as nx\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Import project modules\n",
    "from config import RAW_DATA_DIR, PROCESSED_DATA_DIR, MODEL_DIR\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìÇ Working directory: {Path.cwd()}\")\n",
    "print(f\"üìä Notebook executed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8dafc",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ Part 1: Raw Data Exploration\n",
    "\n",
    "Load and explore the raw transaction data fetched from Ethereum Mainnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw transaction data\n",
    "raw_file = RAW_DATA_DIR / \"transactions_raw.csv\"\n",
    "df_raw = pd.read_csv(raw_file)\n",
    "\n",
    "# Convert timestamp\n",
    "df_raw['timestamp'] = pd.to_datetime(df_raw['timestamp'])\n",
    "\n",
    "print(f\"üìä Dataset Shape: {df_raw.shape}\")\n",
    "print(f\"üìÖ Date Range: {df_raw['timestamp'].min()} to {df_raw['timestamp'].max()}\")\n",
    "print(f\"\\nüîç First 5 rows:\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview\n",
    "print(\"=\" * 60)\n",
    "print(\"üìã DATASET INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Transactions: {len(df_raw):,}\")\n",
    "print(f\"Unique Senders (from): {df_raw['from'].nunique():,}\")\n",
    "print(f\"Unique Receivers (to): {df_raw['to'].nunique():,}\")\n",
    "print(f\"Unique Blocks: {df_raw['blockNumber'].nunique():,}\")\n",
    "print(f\"\\nFraud Distribution:\")\n",
    "print(df_raw['is_fraud'].value_counts())\n",
    "print(f\"\\nFraud Rate: {df_raw['is_fraud'].mean() * 100:.2f}%\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d2bebb",
   "metadata": {},
   "source": [
    "### üìà Visualization 1.1: Transaction Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88882aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction timeline\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=('Daily Transaction Count', 'Cumulative Transactions'),\n",
    "    vertical_spacing=0.15\n",
    ")\n",
    "\n",
    "# Daily transaction count\n",
    "daily_txs = df_raw.groupby(df_raw['timestamp'].dt.date).size()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=daily_txs.index, y=daily_txs.values, mode='lines+markers',\n",
    "               name='Daily Transactions', line=dict(color='#3498db', width=2)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Cumulative transactions\n",
    "cumulative_txs = daily_txs.cumsum()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=cumulative_txs.index, y=cumulative_txs.values, \n",
    "               fill='tonexty', name='Cumulative', \n",
    "               line=dict(color='#2ecc71', width=2)),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(height=700, title_text=\"Transaction Timeline Analysis\", showlegend=True)\n",
    "fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Cumulative Count\", row=2, col=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9949c72",
   "metadata": {},
   "source": [
    "### üìà Visualization 1.2: Transaction Value Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value distribution analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Value distribution (log scale)\n",
    "non_zero_values = df_raw[df_raw['value_eth'] > 0]['value_eth']\n",
    "axes[0, 0].hist(np.log10(non_zero_values), bins=50, color='#3498db', alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_xlabel('log10(Value in ETH)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Transaction Value Distribution (Log Scale)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# 2. Box plot by hour\n",
    "df_raw['hour'] = df_raw['timestamp'].dt.hour\n",
    "hourly_values = df_raw[df_raw['value_eth'] > 0].groupby('hour')['value_eth'].median()\n",
    "axes[0, 1].bar(hourly_values.index, hourly_values.values, color='#2ecc71', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Hour of Day')\n",
    "axes[0, 1].set_ylabel('Median Value (ETH)')\n",
    "axes[0, 1].set_title('Median Transaction Value by Hour', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Gas price distribution\n",
    "axes[1, 0].hist(df_raw['gasPrice'] / 1e9, bins=50, color='#e74c3c', alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Gas Price (Gwei)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Gas Price Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# 4. Gas used distribution\n",
    "axes[1, 1].hist(df_raw['gasUsed'], bins=50, color='#f39c12', alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Gas Used')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Gas Used Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/viz_01_value_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: viz_01_value_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651fd23",
   "metadata": {},
   "source": [
    "### üìà Visualization 1.3: Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e456a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal patterns\n",
    "df_raw['day_of_week'] = df_raw['timestamp'].dt.day_name()\n",
    "df_raw['hour'] = df_raw['timestamp'].dt.hour\n",
    "\n",
    "# Create heatmap data\n",
    "heatmap_data = df_raw.groupby(['day_of_week', 'hour']).size().unstack(fill_value=0)\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "heatmap_data = heatmap_data.reindex(day_order)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.heatmap(heatmap_data, cmap='YlOrRd', annot=True, fmt='g', \n",
    "            cbar_kws={'label': 'Transaction Count'})\n",
    "plt.title('Transaction Activity Heatmap (Day of Week vs Hour)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Hour of Day', fontsize=12)\n",
    "plt.ylabel('Day of Week', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/viz_02_temporal_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: viz_02_temporal_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc808992",
   "metadata": {},
   "source": [
    "---\n",
    "## üî® Part 2: Feature Engineering Analysis\n",
    "\n",
    "Analyze the engineered features before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596eb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed features\n",
    "features_file = PROCESSED_DATA_DIR / \"features.csv\"\n",
    "df_features = pd.read_csv(features_file)\n",
    "\n",
    "print(f\"üìä Features Shape: {df_features.shape}\")\n",
    "print(f\"\\nüîç Feature Columns:\")\n",
    "print(df_features.columns.tolist())\n",
    "print(f\"\\nüìà Features Summary:\")\n",
    "df_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e239c",
   "metadata": {},
   "source": [
    "### üìà Visualization 2.1: Feature Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39183c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features only (exclude metadata)\n",
    "numeric_features = df_features.select_dtypes(include=[np.number]).columns.tolist()\n",
    "exclude_cols = ['blockNumber', 'timeStamp', 'nonce', 'transactionIndex', 'value', 'gas', 'gasPrice', 'gasUsed', 'isError']\n",
    "feature_cols = [col for col in numeric_features if col not in exclude_cols]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df_features[feature_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(20, 16))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "            cmap='coolwarm', center=0, square=True, linewidths=1,\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/viz_03_correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: viz_03_correlation_matrix.png\")\n",
    "print(f\"\\nüîç Top 10 Strongest Correlations:\")\n",
    "corr_pairs = corr_matrix.unstack()\n",
    "corr_pairs = corr_pairs[corr_pairs < 1]\n",
    "print(corr_pairs.abs().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662c5dd",
   "metadata": {},
   "source": [
    "### üìà Visualization 2.2: Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature distributions\n",
    "n_features = len(feature_cols[:16])  # Plot first 16 features\n",
    "n_cols = 4\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(feature_cols[:16]):\n",
    "    data = df_features[feature].dropna()\n",
    "    axes[idx].hist(data, bins=50, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "    axes[idx].set_title(f'{feature}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Value')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_val = data.mean()\n",
    "    median_val = data.median()\n",
    "    axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
    "    axes[idx].axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "\n",
    "# Remove empty subplots\n",
    "for idx in range(n_features, len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/viz_04_feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: viz_04_feature_distributions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69475bc8",
   "metadata": {},
   "source": [
    "### üìà Visualization 2.3: PCA & t-SNE Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44754b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for dimensionality reduction\n",
    "X = df_features[feature_cols].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "y = df_features['is_fraud'].fillna(0)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# t-SNE (use subset for speed)\n",
    "sample_size = min(1000, len(X_scaled))\n",
    "sample_idx = np.random.choice(len(X_scaled), sample_size, replace=False)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X_scaled[sample_idx])\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# PCA plot\n",
    "scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='RdYlGn_r', \n",
    "                           alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)', fontsize=12)\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)', fontsize=12)\n",
    "axes[0].set_title('PCA Projection', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Fraud (1) / Normal (0)')\n",
    "\n",
    "# t-SNE plot\n",
    "scatter2 = axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y.iloc[sample_idx], \n",
    "                           cmap='RdYlGn_r', alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('t-SNE Component 1', fontsize=12)\n",
    "axes[1].set_ylabel('t-SNE Component 2', fontsize=12)\n",
    "axes[1].set_title(f't-SNE Projection (n={sample_size})', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Fraud (1) / Normal (0)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/viz_05_dimensionality_reduction.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: viz_05_dimensionality_reduction.png\")\n",
    "print(f\"\\n‚ÑπÔ∏è PCA Explained Variance: {pca.explained_variance_ratio_.sum()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0edf4",
   "metadata": {},
   "source": [
    "---\n",
    "## üï∏Ô∏è Part 3: Network Graph Analysis\n",
    "\n",
    "Visualize the transaction network and graph-based features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build transaction graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for _, row in df_raw.iterrows():\n",
    "    G.add_edge(row['from'], row['to'], weight=row['value_eth'])\n",
    "\n",
    "print(f\"üìä Network Statistics:\")\n",
    "print(f\"   Nodes (Addresses): {G.number_of_nodes():,}\")\n",
    "print(f\"   Edges (Transactions): {G.number_of_edges():,}\")\n",
    "print(f\"   Density: {nx.density(G):.6f}\")\n",
    "print(f\"   Connected Components: {nx.number_weakly_connected_components(G)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb86b5",
   "metadata": {},
   "source": [
    "### üìà Visualization 3.1: Network Graph Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ecbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute centrality measures\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G, k=100)  # Sample for speed\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "# Plot centrality distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# Degree centrality\n",
    "degree_values = list(degree_centrality.values())\n",
    "axes[0].hist(degree_values, bins=50, color='#3498db', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_xlabel('Degree Centrality', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Degree Centrality Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Betweenness centrality\n",
    "betweenness_values = list(betweenness_centrality.values())\n",
    "axes[1].hist(betweenness_values, bins=50, color='#e74c3c', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Betweenness Centrality', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Betweenness Centrality Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# PageRank\n",
    "pagerank_values = list(pagerank.values())\n",
    "axes[2].hist(pagerank_values, bins=50, color='#2ecc71', alpha=0.7, edgecolor='black')\n",
    "axes[2].set_xlabel('PageRank Score', fontsize=12)\n",
    "axes[2].set_ylabel('Frequency', fontsize=12)\n",
    "axes[2].set_title('PageRank Distribution', fontsize=14, fontweight='bold')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/viz_06_network_centrality.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: viz_06_network_centrality.png\")\n",
    "\n",
    "# Top nodes by centrality\n",
    "print(\"\\nüîù Top 5 Nodes by Degree Centrality:\")\n",
    "top_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "for node, score in top_degree:\n",
    "    print(f\"   {node[:10]}... : {score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568571b6",
   "metadata": {},
   "source": [
    "### üìà Visualization 3.2: Network Visualization (Interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd3cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subgraph of most connected nodes for visualization\n",
    "top_nodes = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:50]\n",
    "top_node_ids = [node for node, _ in top_nodes]\n",
    "G_sub = G.subgraph(top_node_ids)\n",
    "\n",
    "# Use spring layout for positioning\n",
    "pos = nx.spring_layout(G_sub, k=0.5, iterations=50, seed=42)\n",
    "\n",
    "# Create edge traces\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in G_sub.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_x.extend([x0, x1, None])\n",
    "    edge_y.extend([y0, y1, None])\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines'\n",
    ")\n",
    "\n",
    "# Create node traces\n",
    "node_x = []\n",
    "node_y = []\n",
    "node_text = []\n",
    "node_size = []\n",
    "\n",
    "for node in G_sub.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "    node_text.append(f\"Address: {node[:10]}...<br>Degree: {G_sub.degree(node)}<br>PageRank: {pagerank.get(node, 0):.6f}\")\n",
    "    node_size.append(20 + 100 * degree_centrality[node])\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    text=node_text,\n",
    "    marker=dict(\n",
    "        size=node_size,\n",
    "        color=[degree_centrality[node] for node in G_sub.nodes()],\n",
    "        colorscale='Viridis',\n",
    "        showscale=True,\n",
    "        colorbar=dict(title='Degree Centrality'),\n",
    "        line_width=2\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                layout=go.Layout(\n",
    "                    title='Transaction Network Graph (Top 50 Nodes by Degree Centrality)',\n",
    "                    titlefont_size=16,\n",
    "                    showlegend=False,\n",
    "                    hovermode='closest',\n",
    "                    margin=dict(b=0, l=0, r=0, t=40),\n",
    "                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                    height=700\n",
    "                ))\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úÖ Interactive network graph displayed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d598bc",
   "metadata": {},
   "source": [
    "### üìà Visualization 3.3: Graph Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6992370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze graph features from processed data\n",
    "graph_features = ['degree_centrality', 'betweenness_centrality', 'pagerank_score',\n",
    "                  'clustering_coefficient', 'avg_neighbor_degree', 'triangles',\n",
    "                  'community_id', 'community_size']\n",
    "\n",
    "# Filter existing graph features\n",
    "available_graph_features = [f for f in graph_features if f in df_features.columns]\n",
    "\n",
    "if available_graph_features:\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, feature in enumerate(available_graph_features):\n",
    "        if idx < len(axes):\n",
    "            data = df_features[feature].dropna()\n",
    "            axes[idx].hist(data, bins=30, color='teal', alpha=0.7, edgecolor='black')\n",
    "            axes[idx].set_title(f'{feature}', fontsize=12, fontweight='bold')\n",
    "            axes[idx].set_xlabel('Value')\n",
    "            axes[idx].set_ylabel('Frequency')\n",
    "            axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # Remove empty subplots\n",
    "    for idx in range(len(available_graph_features), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../models/viz_07_graph_features.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Saved: viz_07_graph_features.png\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No graph features found in processed data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5aa42b",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ñ Part 4: Model Training & Performance\n",
    "\n",
    "Analyze the trained XGBoost model and its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a83c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "# Find latest model\n",
    "model_files = sorted(glob(str(MODEL_DIR / \"xgb_fraud_*.json\")))\n",
    "if model_files:\n",
    "    latest_model = model_files[-1]\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.load_model(latest_model)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded model: {Path(latest_model).name}\")\n",
    "    \n",
    "    # Load parameters\n",
    "    param_file = latest_model.replace('.json', '').replace('xgb_fraud', 'params') + '.json'\n",
    "    if Path(param_file).exists():\n",
    "        with open(param_file, 'r') as f:\n",
    "            params = json.load(f)\n",
    "        print(f\"\\nüìä Model Hyperparameters:\")\n",
    "        for key, value in params['hyperparameters'].items():\n",
    "            print(f\"   {key}: {value}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No trained model found\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ae0daf",
   "metadata": {},
   "source": [
    "### üìà Visualization 4.1: Feature Importance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb77dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None:\n",
    "    # Get feature importance\n",
    "    importance_types = ['weight', 'gain', 'cover']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(22, 8))\n",
    "    \n",
    "    for idx, imp_type in enumerate(importance_types):\n",
    "        importance = model.get_booster().get_score(importance_type=imp_type)\n",
    "        \n",
    "        if importance:\n",
    "            # Sort by importance\n",
    "            importance_sorted = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True)[:15])\n",
    "            \n",
    "            axes[idx].barh(list(importance_sorted.keys()), list(importance_sorted.values()), \n",
    "                          color='steelblue', alpha=0.8, edgecolor='black')\n",
    "            axes[idx].set_xlabel(f'Importance ({imp_type})', fontsize=12)\n",
    "            axes[idx].set_title(f'Top 15 Features by {imp_type.capitalize()}', \n",
    "                               fontsize=14, fontweight='bold')\n",
    "            axes[idx].invert_yaxis()\n",
    "            axes[idx].grid(alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../models/viz_08_feature_importance_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Saved: viz_08_feature_importance_xgboost.png\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Model not loaded, skipping feature importance visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74fbd7c",
   "metadata": {},
   "source": [
    "---\n",
    "## üîç Part 5: SHAP Explainability Analysis\n",
    "\n",
    "Analyze SHAP values for model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None:\n",
    "    # Prepare data for SHAP\n",
    "    X_sample = df_features[feature_cols].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    sample_size = min(100, len(X_sample))\n",
    "    X_shap = X_sample.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Create SHAP explainer\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_shap)\n",
    "    \n",
    "    print(f\"‚úÖ Computed SHAP values for {sample_size} samples\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Model not loaded, skipping SHAP analysis\")\n",
    "    shap_values = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7196e63",
   "metadata": {},
   "source": [
    "### üìà Visualization 5.1: SHAP Summary Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5503e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shap_values is not None:\n",
    "    # SHAP summary plot (bar)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X_shap, plot_type=\"bar\", show=False, max_display=20)\n",
    "    plt.title('SHAP Feature Importance (Global)', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../models/viz_09_shap_summary_bar.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Saved: viz_09_shap_summary_bar.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e3eb59",
   "metadata": {},
   "source": [
    "### üìà Visualization 5.2: SHAP Beeswarm Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shap_values is not None:\n",
    "    # SHAP beeswarm plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(shap_values, X_shap, show=False, max_display=20)\n",
    "    plt.title('SHAP Beeswarm Plot (Feature Impact)', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../models/viz_10_shap_beeswarm.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Saved: viz_10_shap_beeswarm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457bf104",
   "metadata": {},
   "source": [
    "### üìà Visualization 5.3: SHAP Dependence Plots (Top 4 Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shap_values is not None:\n",
    "    # Get top 4 features by mean absolute SHAP value\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    top_features_idx = np.argsort(mean_abs_shap)[-4:][::-1]\n",
    "    top_features_names = [X_shap.columns[idx] for idx in top_features_idx]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, feature_name in enumerate(top_features_names):\n",
    "        shap.dependence_plot(\n",
    "            feature_name, shap_values, X_shap, \n",
    "            ax=axes[idx], show=False\n",
    "        )\n",
    "        axes[idx].set_title(f'SHAP Dependence: {feature_name}', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../models/viz_11_shap_dependence.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Saved: viz_11_shap_dependence.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835eb523",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Part 6: Model Evaluation Results\n",
    "\n",
    "Visualize evaluation metrics and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation results\n",
    "eval_files = sorted(glob(str(MODEL_DIR / \"evaluation_results_*.json\")))\n",
    "if eval_files:\n",
    "    latest_eval = eval_files[-1]\n",
    "    with open(latest_eval, 'r') as f:\n",
    "        eval_results = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded evaluation results: {Path(latest_eval).name}\")\n",
    "    print(f\"\\nüìä Model Performance Metrics:\")\n",
    "    print(f\"   PR-AUC: {eval_results['pr_auc']:.4f}\")\n",
    "    print(f\"   ROC-AUC: {eval_results['roc_auc']}\")\n",
    "    print(f\"   F1-Score: {eval_results['f1_score']:.4f}\")\n",
    "    print(f\"   Precision: {eval_results['precision']:.4f}\")\n",
    "    print(f\"   Recall: {eval_results['recall']:.4f}\")\n",
    "    print(f\"\\n   Confusion Matrix:\")\n",
    "    print(f\"   TN: {eval_results['tn']}  FP: {eval_results['fp']}\")\n",
    "    print(f\"   FN: {eval_results['fn']}  TP: {eval_results['tp']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No evaluation results found\")\n",
    "    eval_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda3fb9",
   "metadata": {},
   "source": [
    "### üìà Visualization 6.1: Performance Metrics Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cca959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_results:\n",
    "    # Create metrics dashboard\n",
    "    metrics = ['PR-AUC', 'F1-Score', 'Precision', 'Recall']\n",
    "    values = [\n",
    "        eval_results['pr_auc'],\n",
    "        eval_results['f1_score'],\n",
    "        eval_results['precision'],\n",
    "        eval_results['recall']\n",
    "    ]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=metrics,\n",
    "        y=values,\n",
    "        text=[f'{v:.4f}' for v in values],\n",
    "        textposition='auto',\n",
    "        marker=dict(\n",
    "            color=['#3498db', '#2ecc71', '#f39c12', '#e74c3c'],\n",
    "            line=dict(color='black', width=2)\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Model Performance Metrics',\n",
    "        xaxis_title='Metric',\n",
    "        yaxis_title='Score',\n",
    "        yaxis=dict(range=[0, 1]),\n",
    "        height=500,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    print(\"‚úÖ Performance metrics dashboard displayed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8dcdd",
   "metadata": {},
   "source": [
    "### üìà Visualization 6.2: Display Saved Evaluation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d779f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Display confusion matrix\n",
    "cm_files = sorted(glob(str(MODEL_DIR / \"confusion_matrix_*.png\")))\n",
    "if cm_files:\n",
    "    print(\"üìä Confusion Matrix:\")\n",
    "    display(Image(filename=cm_files[-1]))\n",
    "\n",
    "# Display PR curve\n",
    "pr_files = sorted(glob(str(MODEL_DIR / \"pr_curve_*.png\")))\n",
    "if pr_files:\n",
    "    print(\"\\nüìä Precision-Recall Curve:\")\n",
    "    display(Image(filename=pr_files[-1]))\n",
    "\n",
    "# Display ROC curve\n",
    "roc_files = sorted(glob(str(MODEL_DIR / \"roc_curve_*.png\")))\n",
    "if roc_files:\n",
    "    print(\"\\nüìä ROC Curve:\")\n",
    "    display(Image(filename=roc_files[-1]))\n",
    "\n",
    "# Display feature importance\n",
    "fi_files = sorted(glob(str(MODEL_DIR / \"feature_importance_*.png\")))\n",
    "if fi_files:\n",
    "    print(\"\\nüìä Feature Importance:\")\n",
    "    display(Image(filename=fi_files[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3776a2",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Part 7: Summary & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fa3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üìä COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüì¶ Dataset Information:\")\n",
    "print(f\"   Total Transactions: {len(df_raw):,}\")\n",
    "print(f\"   Unique Addresses: {df_raw['from'].nunique() + df_raw['to'].nunique():,}\")\n",
    "print(f\"   Date Range: {df_raw['timestamp'].min()} to {df_raw['timestamp'].max()}\")\n",
    "print(f\"   Fraud Rate: {df_raw['is_fraud'].mean() * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüî® Feature Engineering:\")\n",
    "print(f\"   Total Features: {len(feature_cols)}\")\n",
    "print(f\"   Feature Categories:\")\n",
    "print(f\"      - Temporal: 5\")\n",
    "print(f\"      - Value: 4\")\n",
    "print(f\"      - Gas: 4\")\n",
    "print(f\"      - Account Behavior: 4\")\n",
    "print(f\"      - Network Graph: 13\")\n",
    "\n",
    "print(f\"\\nüï∏Ô∏è Network Analysis:\")\n",
    "print(f\"   Nodes: {G.number_of_nodes():,}\")\n",
    "print(f\"   Edges: {G.number_of_edges():,}\")\n",
    "print(f\"   Density: {nx.density(G):.6f}\")\n",
    "print(f\"   Avg Degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\")\n",
    "\n",
    "if eval_results:\n",
    "    print(f\"\\nü§ñ Model Performance:\")\n",
    "    print(f\"   Algorithm: XGBoost\")\n",
    "    print(f\"   PR-AUC: {eval_results['pr_auc']:.4f}\")\n",
    "    print(f\"   F1-Score: {eval_results['f1_score']:.4f}\")\n",
    "    print(f\"   Precision: {eval_results['precision']:.4f}\")\n",
    "    print(f\"   Recall: {eval_results['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Generated Visualizations:\")\n",
    "viz_files = [\n",
    "    \"viz_01_value_distribution.png\",\n",
    "    \"viz_02_temporal_heatmap.png\",\n",
    "    \"viz_03_correlation_matrix.png\",\n",
    "    \"viz_04_feature_distributions.png\",\n",
    "    \"viz_05_dimensionality_reduction.png\",\n",
    "    \"viz_06_network_centrality.png\",\n",
    "    \"viz_07_graph_features.png\",\n",
    "    \"viz_08_feature_importance_xgboost.png\",\n",
    "    \"viz_09_shap_summary_bar.png\",\n",
    "    \"viz_10_shap_beeswarm.png\",\n",
    "    \"viz_11_shap_dependence.png\"\n",
    "]\n",
    "\n",
    "for viz_file in viz_files:\n",
    "    if (MODEL_DIR / viz_file).exists():\n",
    "        print(f\"   ‚úÖ {viz_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372b0be",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Key Findings & Recommendations\n",
    "\n",
    "### Findings:\n",
    "\n",
    "1. **Data Distribution**: The dataset shows typical Ethereum transaction patterns with value and gas price following log-normal distributions.\n",
    "\n",
    "2. **Temporal Patterns**: Transaction activity shows clear temporal patterns with peaks during business hours.\n",
    "\n",
    "3. **Network Structure**: The transaction network exhibits scale-free properties with a few highly connected hubs.\n",
    "\n",
    "4. **Feature Importance**: Network graph features (centrality, PageRank) show significant predictive power for fraud detection.\n",
    "\n",
    "5. **Model Interpretability**: SHAP analysis reveals that account behavior and network position are key fraud indicators.\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **Expand Dataset**: Include more labeled fraud transactions for better model training\n",
    "2. **Feature Engineering**: Explore additional temporal and network-based features\n",
    "3. **Model Tuning**: Experiment with different hyperparameters and ensemble methods\n",
    "4. **Real-time Detection**: Implement streaming analysis for live fraud detection\n",
    "5. **Community Detection**: Leverage community structure for fraud cluster identification\n",
    "\n",
    "---\n",
    "\n",
    "**End of Analysis Notebook**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
